# -*- coding: utf-8 -*-
"""17-Pandas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i6HPlZj4OlHl0YQZl2MrB-dOxeAhYwMl
"""

# Versão da Linguagem Python
from platform import python_version
print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())

"""## Pandas
<details>
    <summary>
        <a class="btnfire small stroke"><em class="fas fa-chevron-circle-down"></em>&nbsp;&nbsp;Clique para mais detalhes</a>
    </summary>
    <br>
    
Pandas é uma ferramenta de análise e manipulação de dados de código aberto, flexível, rápida, poderosa e fácil de usar, construída com base na linguagem de programação Python. <br>
Possui uma sofisticada funcionalidade de indexação que facilita a coleta dos dados, agregações, limpeza e a seleção de subconjuntos de dados. <br>
Pandas é uma excelente ferramenta para Data Munging ou Data Wrangling, ou simplesmente Análise dos Dados.<br>    
O pacote pandas possui duas estruturas de dados básicas:  <br>  
- **Series** é um array unidimensional capaz de conter qualquer tipo de dado (números inteiros, números do tipo float, strings, objetos Python, entre outros).  <br>
- **DataFrame** é uma estrutura de dados de duas dimensões, ou seja, possui linhas e colunas. Normalmente, cada coluna é de um determinado tipo de dado.

</details>
"""

# Verificando a versão instalada do Pandas
!pip show pandas

# Installing a compatible version of NumPy
!pip install numpy==1.26.4

# Importando o pacote Pandas
import pandas as pd

# Importando o pacote NumPy
import numpy as np

"""### Series
<details>
    <summary>
        <a class="btnfire small stroke"><em class="fas fa-chevron-circle-down"></em>&nbsp;&nbsp;Clique para mais detalhes</a>
    </summary>
    <br>
    
Método para criar uma série:<br>
s = pd.Series(data, index=index) <br>
Os dados podem ser: <br>
- um dicionário Python; <br>
- um ndarray; <br>
- valores de qualquer tipo de dado. <br>
    
</details>
"""

# Criando uma Series com ndarray
# O índice deve ter o mesmo comprimento dos dados.
# Se nenhum índice for passado, os índices serão atribuídos automaticamente com valores iniciando em zero até o tamanho do comprimento dos dados.
np.random.seed(13)
s1 = pd.Series(np.random.randint(1, 100, size=5), index=["a", "b", "c", "d", "e"])
s1

# Criando uma Series com ndarray sem especificar rótulos para os índices.
np.random.seed(13)
s2 = pd.Series(np.random.randint(1, 100, size=5))
s2

# Criando um dicionário
dicionario = {"b": 1,
              "a": 3,
              "c": 2
             }

# Criando uma Series com dicionário.
# Quando o índice não é informado, o índice da série são as chaves do dicionário.
s3 = pd.Series(dicionario)
s3

# Criando uma Series com dicionário informando rótulos para os índices.
s4 = pd.Series(dicionario, index=["b", "a", "c","k"])
s4

# Criando uma Series com dados do tipo String
s5 = pd.Series(["Daniel", "Jorge", "Rose", "Ana"])
s5

# Verificando o tipo de dado
type(s5)

"""### Slicing de Series"""

# Imprimindo uma Series
s2

# Retornando o primeiro elemento
s2[0]

# Retornando os elementos da posição de índice zero até a posição de índice três. A posição de índice 3 é exclusiva.
s2[:3]

# Retornando elementos informando as posições
s2[[4, 2, 0]]

# Imprimindo uma Series
s4

# Retornando elemento a partir dos rótulos dos índices
s4["c"]

# Retornando elemento a partir do índice
s4[2]

# Retornando elementos a partir de uma lista de rótulos dos índices
s4[["k","c"]]

# Retorna elementos de acordo o índice
# Notação de slicing
s4.iloc[2]

# Retorna elementos de acordo com o índice.
# Python mantém os índices mesmo definindo rótulos.
# Notação de slicing
s4.iloc[1:3]

# Retorna elementos de acordo o rótulo do índice
# Notação de slicing
s4.loc["a"]

"""### Pesquisando elementos em uma Series"""

# Imprimindo uma Series
s1

# Utilizando o operador in
"a" in s1

# Pesquisando valores maiores que 50
s1[s1 > 50]

# Pesquisando valores maiores que 50 e menores que 90.
s1[(s1 > 50) & (s1 < 90)]

"""### Métodos e atributos de uma Series"""

# Imprimindo uma Series
s4

# Retornando os valores de uma Series
s4.values

# Retornando os índices de uma Series
s4.index

# Retornando o tipo de dado dos valores de uma Series
s4.dtype

# Atribuinto um nome a Series
s4.name = "Minha Série"

# Retornando o nome de uma Series
s4.name

# Calculando a média dos valores da Series
s4.mean()

# Concatenando Series
novaSerie = pd.concat([s4, s2])
novaSerie

# Concatenando Series
novaSerie = pd.concat([s4, s2], ignore_index=True)
novaSerie

# Resumo estatístico
s4.describe()

# Verificando se existem valores nulos na Series
pd.isna(s4)

# Utilizando o Help
help(pd.isna)

"""### Operações com Series"""

# Imprimindo uma Series
s1

# Somando uma Series
s1 + s1

# Resultado igual a célula anterior
s1 * 2

# Criando uma Series
np.random.seed(45)
s6 = pd.Series(np.random.randint(1, 100, size=8), index=["z", "b", "c", "d", "e", "f", "g", "h"])
s6

# Imprimindo uma Series
s1

# Somando Series. A operação é realizada entre os índices iguais.
# O interpretador gera valores nulos quando não encontra índices iguais nas duas Series.
# O mesmo se aplica para as operações de subtração, multiplicação e divisão.
s1 + s6

"""### DataFrame
<details>
    <summary>
        <a class="btnfire small stroke"><em class="fas fa-chevron-circle-down"></em>&nbsp;&nbsp;Clique para mais detalhes</a>
    </summary>
    <br>
    
Método básico para criar um DataFrame:<br>
df = pd.DataFrame(data) <br>
Os dados podem ser: <br>
- Listas, Series e Dicionários Python; <br>
- ndarray de duas dimensões; <br>
- a partir de arquivos CSV, Excel, HTML, JSON entre outros. <br>
    
</details>
"""

# Criando um dicionário de Series
dicionario1 = {
    "Coluna1": pd.Series([1.0, 2.0, 3.0], index=["a", "b", "c"]),
    "Coluna2": pd.Series([1.0, 2.0, 3.0, 4.0], index=["a", "b", "c", "d"]),
    "Coluna3": pd.Series(np.random.randint(1, 100, size=5), index=["a", "b", "c", "d", "e"])
    }

# Criando um DataFrame a partir de um dicionário
df1 = pd.DataFrame(dicionario1)
df1

# Criando um dicionário de Listas
dicionario2 = {
    "Quantidade": [12, 3, 4, 16],
    "Valor": [100, 125, 75, 88]
    }

# Criando um DataFrame a partir de um dicionário
df2 = pd.DataFrame(dicionario2)
df2

# Verificando o tipo de dado
type(df2)

"""### Titanic Dataset
https://www.kaggle.com/c/titanic/data
"""

from google.colab import drive
drive.mount('/content/drive')

# Criando um DataFrame a partir de um arquivo CSV
# ficar atento ao separador de colunas (atributo "sep") pode ser ";" "," "|"
df3 = pd.read_csv('/content/drive/MyDrive/Dados/Titanic/train.csv', sep = ',', encoding = 'latin-1')
df3

# Criando um DataFrame a partir de um arquivo Excel
df = pd.read_excel("/content/drive/MyDrive/Dados/nomeDoArquivo.xlsx", sheet_name="nome da planilha")

"""### Slicing de DataFrames"""

# Retornando valores de uma coluna.
# Notação de slicing
df3["Name"]

# Exibindo todas as linhas do DataFrame
pd.set_option('display.max_rows', df3.shape[0])

# Retornando uma coluna.
# Coluna como um atributo do DataFrame
df3.Name

# Retornando várias colunas
df3[["Name", "Sex", "Age", "Survived"]]

# Retornando um intervalo de linhas. A linha com índice 3 é exclusiva.
df3[0:3]

# Retornando linhas e colunas específicas
df3[["Name", "Sex", "Age", "Survived"]][0:3]

# Retornando um intervalo de linhas.
# Notação de slicing
df3.iloc[25:32]

# Imprimindo um DataFrame
df1

# Retornando um intervalo de linhas utilizando o rótulo dos índices
df1["b":"d"]

# Retornando linhas específicas
# Notação de slicing
df1.loc[["d","a"]]

"""### Pesquisando registros no DataFrame"""

# Pesquisando um nome específico
df3[df3.Name == "Todoroff, Mr. Lalio"]

# Pesquisando registros em um intervalo da coluna Age.
df3[(df3.Age >= 70) & (df3.Age <= 75)]

# Pesquisando registros utilizando o método Query
df3.query("Survived == 1 and Pclass == 1 and Sex == 'female'")

"""### Métodos e atributos de um DataFrame"""

# Exibindo as primeiras linhas de um DataFrame
df3.head()

# Retornando os índices de um DataFrame.
df3.index

# Retornando o nome das colunas de um DataFrame.
df3.columns

# Retornando os valores das colunas de um DataFrame.
# Os valores são automaticamente convertidos para uma matriz NumPy.
valores = df3.values
valores

# Verificando o tipo de dado.
type(valores)

# Verificando informações sobre cada coluna do DataFrame.
df3.info()

# Verifica o total de valores únicos por coluna.
df3.nunique()

# Verifica o total de valores únicos de um determinada coluna.
df3.Survived.nunique()

# Retorna os valores únicos de uma coluna. Os valores únicos da coluna Embarked são ['S', 'C', 'Q', nan]
df3.Embarked.unique()

# Copiar um DataFrame.
df = df3.copy()
df

# Contando o número de linhas
quantidadeLinhas = df3.shape[0]
quantidadeLinhas

# Contando o número de colunas
quantidadeColunas = df3.shape[1]
quantidadeColunas

# Resumo estatístico das colunas.
df3.describe()

# Contando frequência dos valores de uma variável
df3.Survived.value_counts()

# Renomeando as colunas
# É obrigatório informar todas as colunas
df3.columns = ['ID', 'Sobreviveu', 'Classe', 'Nome', 'Sexo', 'Idade', 'Quantidade de irmãos e esposas', 'Quantidade de pais e filhos', 'Bilhete', 'Tarifa', "Cabine", 'Porto de Embarque']
df3.head(3)

# Renomeando colunas específicas. "inplace = True" salva a alteração diretamente no DataFrame
df3.rename(columns = {"ID":"Código", "Nome":"Nome Completo"}, inplace = True)
df3.head(3)

# Imprimindo um DataFrame
df2

# Adicionando uma linha no final do DataFrame
df2.loc[len(df2.index)] = [30, 5]
df2

# Criando uma nova coluna no DataFrame com valores nulos.
df2["Total"] = np.nan
df2

# Multiplicando colunas.
df2["Total"] = df2["Quantidade"] * df2["Valor"]
df2

# Soma as LINHAS do DataFrame e adiciona uma COLUNA com o total.
# Ficar atento ao intervalo de linhas e colunas especificado no método iloc.
df2["Somatório"] = df2.iloc[:,0:3].sum(numeric_only=True, axis=1)
df2

# Soma as COLUNAS do DataFrame e adiciona uma linha com o total.
# Ficar atento ao intervalo de linhas e colunas especificado no método iloc.
df2.loc['Total'] = df2.iloc[0:4,:].sum(numeric_only=True, axis=0)
df2

# Excluir coluna pelo índice da mesma
df2 = df2.drop(df2.columns[3], axis=1)
df2

# Excluir colunas específicas
df2 = df2.drop(['Valor', 'Total'], axis=1)
df2

# Excluir linhas específicas
df2 = df2.drop([0,2,'Total'], axis=0)

# É importante reiniciar os índices após a exclusão de linhas
df2.reset_index(inplace = True)
df2

# Excluir linhas baseado em uma condição
df2 = df2.drop(df2[df2.Quantidade <  10].index, axis=0)

# É importante reiniciar os índices após a exclusão de uma linha
df2.reset_index(inplace = True)
df2

# Excluir colunas específicas
df2 = df2.drop(["level_0", "index"], axis=1)
df2

# Definindo rótulos para os índices
df2.index = ["a", "b"]
df2

# Criando um dicionário de Listas
dicionario = {
    "Unidade": ["pacote", "und", "cx", "peça"],
    "Valor": [100, 125, 75, 88]
    }

# Criando um DataFrame a partir de um dicionário
df4 = pd.DataFrame(dicionario)
df4

# Concatenando DataFrames
# Atenção aos valores nulos
dfConcatenados = pd.concat([df2, df4], axis="columns")
dfConcatenados

# Verificando se existem dados duplicados.
# Ocorrem dados duplicados quando uma linha inteira, é igual a outra
dfConcatenados.duplicated().sum()

# Adicionando uma linha no final do DataFrame
dfConcatenados.loc[len(dfConcatenados.index)] = [np.nan, "pacote", 100]
dfConcatenados

# Excluindo as linhas duplicadas mantendo a primeira ocorrência da linha
dfConcatenados.drop_duplicates(ignore_index=True, inplace = True)
dfConcatenados

# Imprimindo um DataFrame
df2

# Alterando um valor específico no DataFrame
# df['nome da coluna'] = df['nome da coluna'].replace(["valor atual 1", "valor atual 2", "valor atual 3"],["novo valor 1", "novo valor 2", "novo valor 3"])
df2['Quantidade'] = df2['Quantidade'].replace([16, 30],[5, 8])
df2

# Alterando valores de uma coluna baseado em uma condição
df2.loc[(df2["Quantidade"] > 1) & (df2["Quantidade"] < 7), "Quantidade"] = 99
df2

# Salvar o DataFrame em um arquivo EXCEL. A pasta onde o arquivo for salvo deve existir.
import os

# Gerando um arquivo Excel a partir de um Dataframe
try:
    df2.to_excel('/content/drive/MyDrive/Dados/teste-df2.xlsx', sheet_name='Planilha1')
    print("Arquivo salvo!")

except OSError as mensagemOSError: # Erro de entrada e saída
    print(mensagemOSError)

# Criando um DataFrame a partir de um arquivo Excell
df4 = pd.read_excel("/content/drive/MyDrive/Dados/teste-df2.xlsx", sheet_name='Planilha1')
df4

# Gerando um arquivo CSV a partir de um Dataframe
df2.to_csv('/content/drive/MyDrive/Dados/teste-df2.csv')

# Criando um DataFrame a partir de um arquivo CSV
df5 = pd.read_csv('Dados/teste-df2.csv')
df5

"""### Coletando amostras de um DataFrame"""

# Selecionando aleatoriamente apenas uma linha
df3.sample()

# Selecionando aleatoriamente um número especificado de linhas. Por exemplo, para selecionar 3 linhas aleatórias, defina n = 3
df3.sample(n=3)

# Permitir uma seleção aleatória da mesma linha mais de uma vez informando replace=True
df3.sample(n=3,replace=True)

# Selecione aleatoriamente uma fração específica do número total de linhas. Por exemplo, se você tiver 100 linhas e definir frac = 0,50,
# obterá uma seleção aleatória de 50% do total de linhas, o que significa que 50 linhas serão selecionadas.
df3.sample(frac=0.50)

"""### Exercícios

Utilize o dataset Titanic para responder o que se pede.

1 - Colete os dados do dataset Titanic e carregue em um DataFrame.
"""

# Coletando os dados
import pandas as pd

df = pd.read_csv('/content/drive/MyDrive/Dados/Titanic/train.csv')

"""2 - Exiba as primeiras linhas do DataFrame."""

# Visualizando as primeiras linhas
df.head()

"""3 - Exiba as dimensões do DataFrame."""

# Visualizando as dimensões
df.shape

"""4 - Exiba informações sobre as colunas."""

# Informações sobre as variáveis
df.info()

"""5 - Exiba um resumo estatístico dos dados."""

# Resumo estatístico.
df.describe()

"""6 - Verifique se a coluna Survived está balanceada. Ou seja, se tem a mesma quantidade para passageiros que sobreviveram e para passageiros que não sobreviveram."""

# Contando a frequência dos valores de uma variável.
df.Survived.value_counts()

"""7 - Verifique o total de valores únicos por coluna."""

# Total de valors únicos por coluna.
df.nunique()

"""8 - Exclua as seguintes colunas: Name, PassengerId, SibSp, Parch, Ticket, Cabin.<br>
Obs.: Crie um novo DataFrame para preservar os dados originais.
"""

# Excluindo colunas
df1 = df.drop(["Name", "PassengerId", "SibSp", "Parch", "Ticket", "Cabin"], axis=1)
df1.head(4)

"""9 - Verifique quantos sobreviventes são do sexo masculino e quantos são do sexo feminino. Depois calcule o percentual de cada em relação ao total de sobreviventes."""

# Sobreviventes do sexo masculino
sobreviventesMasculino = df1.query("Survived == 1 and Sex == 'male'").shape[0]
sobreviventesMasculino

# Sobreviventes do sexo feminino
sobreviventesFeminino = df1.query("Survived == 1 and Sex == 'female'").shape[0]
sobreviventesFeminino

# Percentual de sobreviventes do sexo masculino
(sobreviventesMasculino / len(df1.query("Survived == 1")))*100

# Percentual de sobreviventes do sexo feminino
(sobreviventesFeminino / len(df1.query("Survived == 1")))*100

# NÃO Sobreviventes do sexo masculino
naoSobreviventesMasculino = df1.query("Survived == 0 and Sex == 'male'").shape[0]
naoSobreviventesMasculino

# NÃO Sobreviventes do sexo feminino
naoSobreviventesFeminino = df1.query("Survived == 0 and Sex == 'female'").shape[0]
naoSobreviventesFeminino

# Percentual de NÃO sobreviventes do sexo masculino
(naoSobreviventesMasculino / len(df1.query("Survived == 0")))*100

# Percentual de NÃO sobreviventes do sexo feminino
(naoSobreviventesFeminino / len(df1.query("Survived == 0")))*100

